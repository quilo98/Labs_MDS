{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyecto 1 - MDS7202 Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos üìö**\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Ignacio Meza, Gabriel Iturra\n",
    "- Auxiliar: Sebasti√°n Tinoco\n",
    "- Ayudante: Arturo Lazcano, Angelo Mu√±oz\n",
    "\n",
    "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Daniel Quilodr√°n\n",
    "- Katherine Rutte\n",
    "\n",
    "\n",
    "### Link de repositorio de GitHub: ``https://github.com/quilo98/Labs_MDS``\n",
    "\n",
    "Fecha l√≠mite de entrega üìÜ: 27 de Octubre de 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Reglas\n",
    "\n",
    "- **Grupos de 2 personas.**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Estrictamente prohibida la copia. \n",
    "- Pueden usar cualquier material del curso que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://worldskateamerica.org/wp-content/uploads/2023/07/SANTIAGO-2023-1-768x153.jpg\" alt=\"Descripci√≥n de la imagen\">\n",
    "</div>\n",
    "\n",
    "En un Chile azotado por un profundo caos pol√≠tico-econ√≥mico y el resurgimiento de programas de televisi√≥n de dudosa calidad, todas las miradas y esperanzas son depositadas en el √©xito de un √∫nico evento: Santiago 2023. La naci√≥n necesitaba desesperadamente un respiro, y los Juegos de Santiago 2023 promet√≠an ser una luz al final del t√∫nel.\n",
    "\n",
    "El Presidente de la Rep√∫blica -conocido en las calles como Bomb√≠n-, consciente de la importancia de este evento para la revitalizaci√≥n del pa√≠s, decide convocar a usted y su equipo en calidad de expertos en an√°lisis de datos y estad√≠sticas. Con gran solemnidad, el presidente les encomienda una importante y peligrosa: liderar un proyecto que permitiera caracterizar de forma autom√°tica y eficiente los datos generados por estos magnos juegos. Para esto, el presidente le destaca que la soluci√≥n debe considerar los siguientes puntos:\n",
    "- Caracterizaci√≥n autom√°tica de los datos\n",
    "- La soluci√≥n debe ser compatible con cualquier dataset\n",
    "- Se les facilita el dataset *olimpiadas.parquet*, el cual recopila data de diferentes juegos ol√≠mpicos realizados en los √∫ltimos a√±os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creaci√≥n de `Profiler` Class (4.0 puntos)\n",
    "\n",
    "Cree la clase `Profiler`. Como m√≠nimo, esta debe tener las siguientes funcionalidades:\n",
    "\n",
    "1. El m√©todo constructor, el cual debe recibir los datos a procesar en formato `Pandas DataFrame`. Adem√°s, este m√©todo debe generar una carpeta en su directorio de trabajo con el nombre `EDA_fecha`, donde `fecha` corresponda a la fecha de ejecuci√≥n en formato `DD-MM-YYYY`.\n",
    "\n",
    "2. El m√©todo `summarize`, el cual debe caracterizar las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Reportar el tipo de variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores √∫nicos de la variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores nulos\n",
    "    - Si la variables es num√©rica:\n",
    "        - Reportar el n√∫mero y/o porcentaje de valores cero, negativos y outliers\n",
    "        - Reportar estad√≠stica descriptiva como el valor m√≠nimo, m√°ximo, promedio y los percentiles 25, 50, 75 y 100\n",
    "   - Levantar una alerta en caso de encontrar alguna anomal√≠a fuera de lo com√∫n (el criterio debe ser ajustable por el usuario)\n",
    "   - Guardar sus resultados en el directorio `EDA_fecha/summary.txt`. El archivo debe separar de forma clara y ordenada los resultados de cada punto.\n",
    "\n",
    "3. El m√©todo `plot_vars`, el cual debe graficar la distribuci√≥n e interraciones de las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/plots`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Para las variables num√©ricas:\n",
    "        - Genere un gr√°fico de distribuci√≥n de densidad\n",
    "        - Grafique la correlaci√≥n entre las variables\n",
    "    - Para las variables categ√≥ricas:\n",
    "        - Genere un histograma de las top N categor√≠as (N debe ser un par√°metro ajustable)\n",
    "        - Grafique el coeficiente V de Cramer entre las variables\n",
    "    - Guardar cada gr√°fico generado en la carpeta `EDA_fecha/plots` en formato `.pdf` y bajo el naming `variable.pdf`, donde `variable` es el nombre de la variable de inter√©s\n",
    "    \n",
    "4. El m√©todo `clean_data`, el cual debe limpiar los datos para que luego puedan ser procesados. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clean_data`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Drop de valores duplicados\n",
    "    - Implementar como m√≠nimo 2 t√©cnicas para tratar los valores nulos, como:\n",
    "        - Drop de valores nulos\n",
    "        - Imputar valores nulos con alguna t√©cnica de imputaci√≥n\n",
    "        - Funcionalidad para escoger entre una t√©cnica y la otra.\n",
    "    - Una de las columnas del dataframe presenta datos *no at√≥micos*. Separe dicha columna en las columnas que la compongan.\n",
    "        - Hint: ¬øQu√© caracteres permiten separar una columna de otra?\n",
    "        - Para las pruebas con el dataset nuevo, puede esperar que exista al menos una columna con este tipo de problema. Asuma que los separadores ser√°n los mismos, aunque el n√∫mero de columnas a separar puede ser distinto.\n",
    "    - Deber√≠an usar `FunctionTransformer`.\n",
    "    - Guardar los datos procesados en formato `.csv` en el path `EDA_fecha/clean_data/data.csv`\n",
    "\n",
    "5. El m√©todo `scale`, el cual debe preparar adecuadamente los datos para luego ser consumidos por alg√∫n tipo de algoritmo. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/scale`\n",
    "    - Procesar de forma adecuada los datos num√©ricos y categ√≥ricos:\n",
    "        - Su m√©todo debe recibir las t√©cnicas de escalamiento como argumento de entrada (utilizar solo t√©cnicas compatibles con el framework de `sklearn`)\n",
    "        - Para los atributos num√©ricos, se transforme los datos con un escalador logar√≠tmico y un `MinMaxScaler`\n",
    "        - Asuma que no existen datos ordinales en su dataset\n",
    "    - Guardar todo este procesamiento en un `ColumnTransformer`.\n",
    "    - Guardar los datos limpios y transformados en formato `.csv` en el path `EDA_fecha/process/scaled_features.csv`\n",
    "\n",
    "6. El m√©todo `make_clusters`, el cual debe generar clusters de los datos usando alg√∫n algoritmo de clusterizaci√≥n. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clusters`\n",
    "    - Generar un estudio del codo donde se√±ale la cantidad de clusters optimos para el desarrollo.\n",
    "    - Su m√©todo debe recibir el algoritmo de clustering como argumento de entrada (utilizar solo algoritmos compatibles con el framework de `sklearn`).\n",
    "    - No olvide pre procesar adecuadamente los datos antes de implementar la t√©cnica de clustering. \n",
    "    - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "    - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "    - Una vez generado los clusters, proyecte los datos a 2 dimensiones usando su t√©cnica de reducci√≥n de dimensionalidad favorita y grafique los resultados coloreando por cluster.\n",
    "    - Guardar los datos con su respectivo cluster en formato `.csv` en el path `EDA_fecha/clusters/data_clusters.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "7. El m√©todo `detect_anomalies`, el cual debe detectar anomal√≠as en los datos. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "\n",
    "    - Crear la carpeta `EDA_fecha/anomalies`\n",
    "    - Implementar alguna t√©cnica de detecci√≥n de anomal√≠as.\n",
    "    - Al igual que el punto anterior, su m√©todo debe considerar los siguientes puntos:\n",
    "        - No olvide pre procesar de forma adecuada los datos antes de implementar la t√©cnica de detecci√≥n de anomal√≠a. \n",
    "        - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "        - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "        - Su m√©todo debe recibir el algoritmo como argumento de entrada\n",
    "        - Una vez generado las etiquetas, proyecte los datos a 2 dimensiones y grafique los resultados coloreando por las etiquetas predichas por el detector de anomal√≠as\n",
    "    - Guardar los datos con su respectiva etiqueta en formato `.csv` en el path `EDA_fecha/anomalies/data_anomalies.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "8. El m√©todo `profile`, el cual debe ejecutar todos los m√©todos anteriores.\n",
    "\n",
    "9. Crear el m√©todo `clearGarbage` para eliminar las carpetas/archivos creados/as por la clase `Profiler`.\n",
    "\n",
    "Algunas consideraciones generales:\n",
    "- Su clase ser√° testeada con datos tabulares diferentes a los provistos. No desarrollen c√≥digo *hardcodeado*: su clase debe ser capaz de funcionar para **cualquier** dataset. \n",
    "- Aplique todo su conocimiento sobre buenas pr√°cticas de programaci√≥n: se evaluar√° que su c√≥digo sea limpio y ordenado.\n",
    "- Recuerden documentar cada una de las funcionalidades que implementen.\n",
    "- Recuerden adjuntar sus `requirements.txt` junto a su entrega de proyecto. **El c√≥digo que no se pueda ejecutar por imcompatibilidades de librer√≠as no ser√° corregido.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from IPython.display import HTML\n",
    "#Libreria para plotear\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import shutil\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age-height-weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>None</td>\n",
       "      <td>24.0*180.0?80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>None</td>\n",
       "      <td>23.0(170.0?60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>None</td>\n",
       "      <td>24.0(nan?nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "      <td>34.0:nan?nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>None</td>\n",
       "      <td>21.0(185.0?82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                      Name Sex            Team  NOC        Games  Year  \\\n",
       "0   1                 A Dijiang   M           China  CHN  1992 Summer  1992   \n",
       "1   2                  A Lamusi   M           China  CHN  2012 Summer  2012   \n",
       "2   3       Gunnar Nielsen Aaby   M         Denmark  DEN  1920 Summer  1920   \n",
       "3   4      Edgar Lindenau Aabye   M  Denmark/Sweden  DEN  1900 Summer  1900   \n",
       "4   5  Christine Jacoba Aaftink   F     Netherlands  NED  1988 Winter  1988   \n",
       "\n",
       "   Season       City          Sport                             Event Medal  \\\n",
       "0  Summer  Barcelona     Basketball       Basketball Men's Basketball  None   \n",
       "1  Summer     London           Judo      Judo Men's Extra-Lightweight  None   \n",
       "2  Summer  Antwerpen       Football           Football Men's Football  None   \n",
       "3  Summer      Paris     Tug-Of-War       Tug-Of-War Men's Tug-Of-War  Gold   \n",
       "4  Winter    Calgary  Speed Skating  Speed Skating Women's 500 metres  None   \n",
       "\n",
       "  age-height-weight  \n",
       "0   24.0*180.0?80.0  \n",
       "1   23.0(170.0?60.0  \n",
       "2      24.0(nan?nan  \n",
       "3      34.0:nan?nan  \n",
       "4   21.0(185.0?82.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizamos el dataset para ver con que variables nos podemos encontrar y asi tener una idea\n",
    "df = pd.read_parquet('olimpiadas.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paleta de colores de los Juegos Panamericanos Santiago 2023\n",
    "\n",
    "# Define los colores en formato hexadecimal\n",
    "colores = [\"#0074FF\", \"#FE4F3A\", \"#FFD200\", \"#00CCCC\"]\n",
    "\n",
    "# Crea la paleta personalizada\n",
    "stgo2023 = sns.color_palette(colores)\n",
    "\n",
    "# Configura Seaborn para utilizar la paleta personalizada\n",
    "sns.set_palette(stgo2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos semilla\n",
    "random_state=random.seed(42)\n",
    "random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profiler:\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\"\n",
    "        Constructor de la clase Profiler.\n",
    "\n",
    "        Par√°metros:\n",
    "        data_file (str): La ruta del archivo de datos que se desea analizar. \n",
    "        \"\"\"\n",
    "        self.data_file = data_file\n",
    "        self.cleaned_data = None  # A√±ade un atributo para la data procesada\n",
    "        self.scaled_data = None # A√±ade un atributo para la data escalada\n",
    "        self.cluster_data = None #A√±ade un atributo para la data clusterizada\n",
    "        self.anomalies_data = None #A√±ade un atributo para la data con anomalias\n",
    "        self.date = dt.datetime.now().strftime(\"%d-%m-%Y\")\n",
    "        self.output_dir = \"EDA_{}\".format(self.date)\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "\n",
    "        # Intenta cargar el archivo en un DataFrame de Pandas\n",
    "        try:\n",
    "            if data_file.lower().endswith('.csv'):\n",
    "                self.data = pd.read_csv(data_file)\n",
    "            elif data_file.lower().endswith(('.xls', '.xlsx')):\n",
    "                self.data = pd.read_excel(data_file)\n",
    "            elif data_file.lower().endswith('.parquet'):\n",
    "                self.data = pd.read_parquet(data_file)\n",
    "            else:\n",
    "                raise ValueError(\"Formato de archivo no compatible. Solo se admiten archivos CSV, Excel y Parquet.\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"No se pudo cargar el archivo: {str(e)}\")\n",
    "\n",
    "    def summarize(self, columns=None, anomaly_threshold=0.05):\n",
    "        \"\"\"\n",
    "        Caracteriza las variables del DataFrame y guarda los resultados en un archivo summary.txt.\n",
    "\n",
    "        Par√°metros:\n",
    "        columns (list): Lista de nombres de las columnas a analizar. Si es None, se analizar√°n todas las columnas.\n",
    "        anomaly_threshold (float): Umbral para detectar anomal√≠as en porcentaje. Por defecto, 0.05 (5%).\n",
    "\n",
    "        Nota: anomaly_threshold es el porcentaje de valores √∫nicos para considerar una variable como an√≥mala.\n",
    "        \"\"\"\n",
    "        summary_file = os.path.join(self.output_dir, \"summary.txt\")\n",
    "\n",
    "        with open(summary_file, \"w\") as f:\n",
    "            f.write(f\"Resumen del An√°lisis - Fecha: {self.date}\\n\\n\")\n",
    "\n",
    "            if columns is None:\n",
    "                columns = self.data.columns\n",
    "\n",
    "            for col in columns:\n",
    "                f.write(f\"Variable: {col}\\n\")\n",
    "                variable = self.data[col]\n",
    "                variable_type = variable.dtype\n",
    "                num_unique = variable.nunique()\n",
    "                num_null = variable.isnull().sum()\n",
    "                f.write(f\"Tipo de Variable: {variable_type}\\n\")\n",
    "                f.write(f\"N√∫mero de Valores √önicos: {num_unique}\\n\")\n",
    "                f.write(f\"N√∫mero de Valores Nulos: {num_null}\\n\")\n",
    "\n",
    "                if variable_type in [\"int64\", \"float64\"]:\n",
    "                    num_zeros = (variable == 0).sum()\n",
    "                    num_negatives = (variable < 0).sum()\n",
    "                    num_duplicates = variable.duplicated().sum()\n",
    "                    Q1 = variable.quantile(0.25)\n",
    "                    Q3 = variable.quantile(0.75)\n",
    "                    IQR = Q3 - Q1\n",
    "                    lower_limit = Q1 - 1.5 * IQR\n",
    "                    upper_limit = Q3 + 1.5 * IQR\n",
    "                    num_outliers = ((variable < lower_limit) | (variable > upper_limit)).sum()\n",
    "                    descriptive_stats = variable.describe()\n",
    "                    f.write(f\"N√∫mero de Valores Cero: {num_zeros}\\n\")\n",
    "                    f.write(f\"N√∫mero de Valores Negativos: {num_negatives}\\n\")\n",
    "                    f.write(f\"N√∫mero de Valores Duplicados: {num_duplicates}\\n\")\n",
    "                    f.write(f\"N√∫mero de Outliers: {num_outliers}\\n\")\n",
    "                    f.write(\"Estad√≠sticas Descriptivas:\\n\")\n",
    "                    f.write(descriptive_stats.to_string() + \"\\n\")\n",
    "\n",
    "                    # Detectar anomal√≠as basadas en el umbral de porcentaje\n",
    "                    if (num_unique / len(variable)) > anomaly_threshold:\n",
    "                        f.write(\"Anomal√≠a: Esta variable tiene un alto porcentaje de valores √∫nicos.\\n\")\n",
    "                else:\n",
    "                    if num_unique <= 5:\n",
    "                        value_counts = variable.value_counts()\n",
    "                        f.write(\"Frecuencia de Categor√≠as:\\n\")\n",
    "                        for category, count in value_counts.items():\n",
    "                            f.write(f\"{category}: {count}\\n\")\n",
    "                    else:\n",
    "                        top_categories = variable.value_counts().nlargest(5)\n",
    "                        f.write(\"Frecuencia de las 5 Categor√≠as M√°s Frecuentes:\\n\")\n",
    "                        for category, count in top_categories.items():\n",
    "                            f.write(f\"{category}: {count}\\n\")\n",
    "                    f.write(\"No se proporciona informaci√≥n adicional para variables no num√©ricas.\\n\")\n",
    "\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "\n",
    "    def plot_vars(self, columns=None, top_n_categories=5):\n",
    "        \"\"\"\n",
    "        Genera gr√°ficos de distribuci√≥n e interacciones de las variables y los guarda en la carpeta \"plots\".\n",
    "\n",
    "        Par√°metros:\n",
    "        columns (list): Lista de nombres de las columnas a analizar. Si es None, se analizar√°n todas las columnas.\n",
    "        top_n_categories (int): N√∫mero de categor√≠as a mostrar en el histograma para variables categ√≥ricas.\n",
    "        \"\"\"\n",
    "        plots_dir = os.path.join(self.output_dir, \"plots\")\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        if columns is None:\n",
    "            columns = self.data.columns\n",
    "\n",
    "        for col in columns:\n",
    "            variable = self.data[col]\n",
    "            sns.set_palette(stgo2023)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "\n",
    "            if variable.dtype in [\"int64\", \"float64\"]:\n",
    "                # Gr√°fico de distribuci√≥n de densidad para variables num√©ricas\n",
    "                sns.histplot(variable, kde=True)\n",
    "                plt.title(f\"Distribuci√≥n de Densidad de {col}\")\n",
    "            else:\n",
    "                # Histograma de las top N categor√≠as para variables categ√≥ricas\n",
    "                top_categories = variable.value_counts().head(top_n_categories)\n",
    "                sns.barplot(x=top_categories.index, y=top_categories.values)\n",
    "                plt.title(f\"Top {top_n_categories} Categor√≠as de {col}\")\n",
    "                plt.xticks(rotation=20)\n",
    "\n",
    "            plt.xlabel(col)\n",
    "            plt.ylabel(\"Frecuencia\")\n",
    "            plt.savefig(os.path.join(plots_dir, f\"{col}.pdf\"))\n",
    "            plt.close()\n",
    "\n",
    "        #Gr√°fico de correlaci√≥n para variables num√©ricas\n",
    "        num_vars = self.data.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "        if not num_vars.empty:\n",
    "            correlation_matrix = num_vars.corr()\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "            plt.title(\"Correlaci√≥n entre Variables Num√©ricas\")\n",
    "            plt.savefig(os.path.join(plots_dir, \"correlation.pdf\"))\n",
    "            plt.close()\n",
    "\n",
    "        #Gr√°fico del coeficiente V de Cramer entre variables categ√≥ricas\n",
    "        cat_vars = self.data.select_dtypes(include=[\"object\", \"category\"])\n",
    "        if not cat_vars.empty:\n",
    "            n = len(cat_vars.columns)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            cramer_matrix = np.ones((n, n))\n",
    "            for i, col1 in enumerate(cat_vars.columns):\n",
    "                for j, col2 in enumerate(cat_vars.columns):\n",
    "                    if i != j:\n",
    "                        try:\n",
    "                            confusion_matrix = pd.crosstab(cat_vars[col1], cat_vars[col2])\n",
    "                            chi2, _, _, _ = stats.chi2_contingency(confusion_matrix)\n",
    "                            n = confusion_matrix.sum().sum()\n",
    "                            cramer = np.sqrt(chi2 / (n * (min(confusion_matrix.shape) - 1)))\n",
    "                            cramer_matrix[i, j] = cramer\n",
    "                        except:\n",
    "                            # Maneja la excepci√≥n (error) y contin√∫a con las dem√°s columnas\n",
    "                            print(f\"Error al calcular la matriz de confusi√≥n para {col1} y {col2}\")\n",
    "            sns.heatmap(cramer_matrix, annot=True, cmap=\"coolwarm\", xticklabels=cat_vars.columns, yticklabels=cat_vars.columns)\n",
    "            plt.title(\"Coeficiente V de Cramer entre Variables Categ√≥ricas\")\n",
    "            plt.savefig(os.path.join(plots_dir, \"cramer.pdf\"))\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    def clean_data(self, columns=None, drop_nulls=True, impute_strategy=None, impute_strategy_mapper=None):\n",
    "        \"\"\"\n",
    "        Limpia los datos, eliminando valores duplicados, tratando valores nulos y separando columnas no at√≥micas.\n",
    "        Guarda los datos procesados en formato .csv.\n",
    "\n",
    "        Par√°metros:\n",
    "        columns (list): Lista de nombres de las columnas a las que se aplicar√° la limpieza.\n",
    "                        Si es None, se aplicar√° a todas las columnas.\n",
    "        drop_nulls (bool): Si es True, se eliminar√°n las filas con valores nulos. Si es False,\n",
    "                        se imputar√°n los valores nulos con la t√©cnica de imputaci√≥n seleccionada.\n",
    "        impute_strategy (str): Estrategia de imputaci√≥n para valores nulos. Puede ser 'mean', 'median', 'most_frequent', o None.\n",
    "        impute_strategy_mapper (dict): Un mapeo personalizado de estrategias de imputaci√≥n por columna.\n",
    "        \"\"\"\n",
    "        clean_dir = os.path.join(self.output_dir, \"clean_data\")\n",
    "        os.makedirs(clean_dir, exist_ok=True)\n",
    "\n",
    "        # Crear una copia del DataFrame original\n",
    "        cleaned_data = self.data.copy()\n",
    "\n",
    "        if columns is None:\n",
    "            columns = cleaned_data.columns\n",
    "\n",
    "        # Eliminar valores duplicados en la copia\n",
    "        cleaned_data.drop_duplicates(subset=columns, inplace=True)\n",
    "\n",
    "        # Definir caracteres especiales utilizando regex\n",
    "        special_chars = r'[^A-Za-z0-9.]'\n",
    "        columns_to_remove = []\n",
    "        # Identificar columnas no at√≥micas en funci√≥n de caracteres no alfanum√©ricos en los nombres de columna\n",
    "        non_atomic_columns = [col for col in columns if re.search(special_chars, col)]\n",
    "\n",
    "        # Separar columnas no at√≥micas\n",
    "        for col in non_atomic_columns:\n",
    "            if cleaned_data[col].dtype == \"object\":\n",
    "                original_col_names = re.split(special_chars, col) \n",
    "                # Reemplazar caracteres especiales\n",
    "                cleaned_data[col] = cleaned_data[col].str.replace(special_chars, ' ', regex=True)\n",
    "                # Crear nuevas columnas a partir de los datos separados\n",
    "                new_cols = cleaned_data[col].str.split(' ', expand=True)\n",
    "                # Comprobar si el n√∫mero de nuevas columnas es igual al de nombres extra√≠dos, de lo contrario, puede ser un problema\n",
    "                if new_cols.shape[1] != len(original_col_names):\n",
    "                    print(f\"Warning: The number of split parts in '{col}' does not match with expected names {original_col_names}\")\n",
    "                    # Puede querer manejar este caso con l√≥gica adicional o aserciones aqu√≠\n",
    "                \n",
    "                # Asignar los nombres de las columnas originales a las nuevas columnas\n",
    "                new_cols.columns = original_col_names\n",
    "\n",
    "                # Iterar a trav√©s de las nuevas columnas y convertirlas en num√©ricas o dejarlas como objetos\n",
    "                for new_col in new_cols.columns:\n",
    "                    new_cols[new_col] = new_cols[new_col].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "                # A√±adir las nuevas columnas al DataFrame\n",
    "                cleaned_data = pd.concat([cleaned_data, new_cols], axis=1)\n",
    "                columns_to_remove.append(col)\n",
    "\n",
    "\n",
    "        def custom_cleaning(X, drop_nulls, impute_strategy, impute_strategy_mapper):\n",
    "            # Reemplazar 0, 'nan', 'NaN' con np.nan\n",
    "            X.replace([0, 'nan', 'NaN'], np.nan, inplace=True)\n",
    "\n",
    "            for col in X.columns:\n",
    "                if X[col].dtype == 'object' or isinstance(X[col].dtype, pd.CategoricalDtype):\n",
    "                    # Para columnas categ√≥ricas, reemplazar NaN con 'ND'\n",
    "                    X[col].fillna('ND', inplace=True)\n",
    "                else:\n",
    "                    # Si la estrategia de imputaci√≥n no es None, se imputan los valores num√©ricos como se especifica\n",
    "                    if impute_strategy and (col not in X.select_dtypes(include=['object', 'category']).columns):\n",
    "                        if impute_strategy_mapper and col in impute_strategy_mapper:\n",
    "                            impute_strategy_col = impute_strategy_mapper[col]\n",
    "                        else:\n",
    "                            impute_strategy_col = impute_strategy\n",
    "                        \n",
    "                        if impute_strategy_col == 'mean':\n",
    "                            X[col].fillna(X[col].mean(), inplace=True)\n",
    "                        elif impute_strategy_col == 'median':\n",
    "                            X[col].fillna(X[col].median(), inplace=True)\n",
    "                        elif impute_strategy_col == 'most_frequent':\n",
    "                            X[col].fillna(X[col].mode().iloc[0], inplace=True)\n",
    "                        # Si se establece alguna otra estrategia de imputaci√≥n, se coloca aqu√≠\n",
    "                    elif drop_nulls:\n",
    "                        # Para columnas num√©ricas, si se elige eliminar valores nulos, se aplica aqu√≠\n",
    "                        X = X[pd.notnull(X[col])]\n",
    "\n",
    "            return X\n",
    "\n",
    "\n",
    "        # Crear el transformador con FunctionTransformer\n",
    "        cleaning_transformer = FunctionTransformer(\n",
    "            func=custom_cleaning,\n",
    "            validate=False,\n",
    "            kw_args={\n",
    "                'drop_nulls': drop_nulls,\n",
    "                'impute_strategy': impute_strategy,\n",
    "                'impute_strategy_mapper': impute_strategy_mapper\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Aplicar las transformaciones\n",
    "        cleaned_data.drop(columns=columns_to_remove, inplace=True)\n",
    "        cleaned_data = cleaning_transformer.transform(cleaned_data)\n",
    "        processed_data_file = os.path.join(clean_dir, \"data.csv\")\n",
    "        cleaned_data.to_csv(processed_data_file, index=False)\n",
    "        self.cleaned_data = cleaned_data\n",
    "\n",
    "    \n",
    "    def scale(self, categorical_threshold=100):\n",
    "        \"\"\"\n",
    "        Escala los datos utilizando una transformaci√≥n logar√≠tmica seguida de un Min-Max Scaler para variables num√©ricas\n",
    "        y guarda el resultado en un archivo CSV.\n",
    "        \n",
    "        Par√°metros:\n",
    "        \n",
    "        categorical_threshold (int): Umbral para codificar variables categ√≥ricas en one-hot.\n",
    "        \"\"\"\n",
    "        scale_dir = os.path.join(self.output_dir, \"scale\")\n",
    "        os.makedirs(scale_dir, exist_ok=True)\n",
    "\n",
    "        # Si cleaned_data a√∫n no est√° disponible, ejecuta clean_data\n",
    "        if self.cleaned_data is None:\n",
    "            self.clean_data()\n",
    "\n",
    "        # Obtener las columnas num√©ricas y categ√≥ricas\n",
    "        numerical_columns = self.cleaned_data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "        categorical_columns = self.cleaned_data.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "        # Identificar las columnas categ√≥ricas que tienen menos de `categorical_threshold` valores √∫nicos\n",
    "        categorical_columns_to_encode = [col for col in categorical_columns if self.cleaned_data[col].nunique() < categorical_threshold]\n",
    "\n",
    "        # Crear un transformador secuencial para logaritmo y Min-Max Scaler para atributos num√©ricos\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "            ('log_transform', FunctionTransformer(func=np.log1p, validate=False)),\n",
    "            ('minmax_scaler', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "        # Crear un transformador para atributos categ√≥ricos\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder())\n",
    "        ])\n",
    "\n",
    "        # Combinar los transformadores en un ColumnTransformer\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numerical_columns),\n",
    "                ('cat', categorical_transformer, categorical_columns_to_encode)\n",
    "            ])\n",
    "\n",
    "        # Aplicar las transformaciones\n",
    "        scaled_features = preprocessor.fit_transform(self.cleaned_data)\n",
    "        \n",
    "        # Obtener nombres de nuevas columnas despu√©s de one-hot encoding\n",
    "        # Esto es necesario ya que el n√∫mero de columnas aumenta despu√©s del one-hot encoding\n",
    "        new_categorical_features = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_columns_to_encode)\n",
    "\n",
    "        # Combinar todos los nombres de columnas, num√©ricas y categ√≥ricas\n",
    "        all_feature_names = numerical_columns.tolist() + list(new_categorical_features)\n",
    "\n",
    "        # Crear un DataFrame con las caracter√≠sticas escaladas\n",
    "        scaled_features = scaled_features.toarray()\n",
    "        scaled_data = pd.DataFrame(data=scaled_features, columns=all_feature_names)\n",
    "        \n",
    "        # Guardar los datos procesados en formato .csv\n",
    "        scaled_data_file = os.path.join(scale_dir, \"scaled_features.csv\")\n",
    "        scaled_data.to_csv(scaled_data_file, index=False)\n",
    "        self.scaled_data = scaled_data\n",
    "\n",
    "\n",
    "    def make_clusters(self, cluster_algorithm=KMeans, n_clusters_range=range(2, 11)):\n",
    "        \"\"\"\n",
    "        Genera clusters de los datos y guarda los resultados en la carpeta \"clusters\".\n",
    "\n",
    "        Par√°metros:\n",
    "        cluster_algorithm (sklearn.cluster.ClusterMixin): Algoritmo de clustering de scikit-learn (KMeans) por defecto.\n",
    "        n_clusters_range (range): Rango de valores para buscar el n√∫mero √≥ptimo de clusters.\n",
    "        \"\"\"\n",
    "        clusters_dir = os.path.join(self.output_dir, \"clusters\")\n",
    "        os.makedirs(clusters_dir, exist_ok=True)\n",
    "\n",
    "        # Si cleaned_data a√∫n no est√° disponible, ejecuta clean_data y scale\n",
    "        if self.cleaned_data is None:\n",
    "            self.cleaned_data()\n",
    "        if self.scaled_data is None:\n",
    "            self.scale()\n",
    "        cluster_data=self.cleaned_data.copy()\n",
    "        # Realizar el estudio del codo para encontrar el n√∫mero √≥ptimo de clusters en todas las dimensiones originales\n",
    "        distortions = []\n",
    "        for n_clusters in n_clusters_range:\n",
    "            pipeline = Pipeline([\n",
    "                ('cluster', cluster_algorithm(n_clusters=n_clusters, n_init=10))  # Algoritmo de clustering\n",
    "            ])\n",
    "            pipeline.fit(self.scaled_data)\n",
    "            distortions.append(pipeline.named_steps['cluster'].inertia_)\n",
    "\n",
    "        # Graficar el estudio del codo\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(n_clusters_range, distortions, marker='o')\n",
    "        plt.xlabel('N√∫mero de Clusters')\n",
    "        plt.ylabel('Distorsi√≥n')\n",
    "        plt.title('M√©todo del Codo para selecci√≥n del n√∫mero de Clusters')\n",
    "        plt.savefig(os.path.join(clusters_dir, 'Metodo_codo.pdf'))\n",
    "        plt.close()\n",
    "        # Elegir el n√∫mero √≥ptimo de clusters basado en el punto de quiebre en el estudio del codo\n",
    "        optimal_n_clusters = n_clusters_range[np.argmin(np.diff(distortions)) + 1]\n",
    "        print(optimal_n_clusters)\n",
    "        # Realizar clustering con el n√∫mero √≥ptimo de clusters\n",
    "        pipeline = Pipeline([\n",
    "            ('cluster', cluster_algorithm(n_clusters=optimal_n_clusters, n_init=10))  # Algoritmo de clustering\n",
    "        ])\n",
    "        cluster_labels = pipeline.fit_predict(self.scaled_data)\n",
    "\n",
    "        # Agregar la columna de cluster_labels al DataFrame original\n",
    "        cluster_data['Cluster'] = cluster_labels\n",
    "        cluster_data_file = os.path.join(clusters_dir, \"data_clusters.csv\")\n",
    "        cluster_data.to_csv(cluster_data_file, index=False)\n",
    "\n",
    "\n",
    "        # Proyectar los datos a 2 dimensiones\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_data = pca.fit_transform(self.scaled_data)\n",
    "        reduced_data = pd.DataFrame(reduced_data, columns=['Dimension 1', 'Dimension 2'])\n",
    "        reduced_data[\"Cluster\"] = cluster_labels\n",
    "\n",
    "        # Graficar los resultados coloreando por cluster\n",
    "        # Define los colores en formato hexadecimal\n",
    "        colores = [\"#0074FF\", \"#FE4F3A\", \"#FFD200\", \"#00CCCC\"]\n",
    "        # Crea la paleta personalizada\n",
    "        stgo2023 = sns.color_palette(colores)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.scatterplot(x='Dimension 1', y='Dimension 2', hue=reduced_data['Cluster'], data=reduced_data, palette=stgo2023)\n",
    "        plt.title('Proyecci√≥n de Datos en 2 Dimensiones con Coloreo por Cluster')\n",
    "        plt.savefig(os.path.join(clusters_dir, 'cluster_plot.pdf'))\n",
    "\n",
    "        # Guardar los gr√°ficos generados\n",
    "        plt.close()\n",
    "        self.cluster_data=cluster_data\n",
    "\n",
    "\n",
    "    def detect_anomalies(self, algoritmo=IsolationForest(contamination=0.05)):\n",
    "        \"\"\"\n",
    "        Detecta anomal√≠as en los datos y guarda los resultados en la carpeta \"anomalies\".\n",
    "\n",
    "        Par√°metros:\n",
    "        algorithm (str): El algoritmo de detecci√≥n de anomal√≠as a utilizar. Por defecto tenemos 'isolation_forest'.\n",
    "        \"\"\"\n",
    "        anomalies_dir = os.path.join(self.output_dir, \"anomalies\")\n",
    "        os.makedirs(anomalies_dir, exist_ok=True)\n",
    "\n",
    "        # Si los datos no est√°n limpios y escalados, aplique los m√©todos clean_data y scale\n",
    "        if self.cleaned_data is None:\n",
    "            self.clean_data()\n",
    "        if self.scaled_data is None:\n",
    "            self.scale()\n",
    "\n",
    "\n",
    "        anomaly_detection_pipeline = Pipeline([('algoritmo_anomalias', algoritmo)\n",
    "        ])\n",
    "\n",
    "        # Ajustar el modelo de detecci√≥n de anomal√≠as y obtener etiquetas\n",
    "        anomaly_labels = anomaly_detection_pipeline.fit_predict(self.scaled_data)\n",
    "\n",
    "        # Agregar las etiquetas de anomal√≠as al DataFrame de datos\n",
    "        anomalies_data = self.cleaned_data.copy()\n",
    "        anomalies_data['anomaly_labels'] = anomaly_labels\n",
    "\n",
    "        # Guardar los datos con etiquetas de anomal√≠as en formato .csv\n",
    "        anomalies_data_file = os.path.join(anomalies_dir, \"data_anomalies.csv\")\n",
    "        anomalies_data.to_csv(anomalies_data_file, index=False)\n",
    "\n",
    "        # Reducir las dimensiones con PCA para graficar\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_data = pca.fit_transform(self.scaled_data)\n",
    "\n",
    "        # Proyectar los datos a 2 dimensiones y graficar los resultados\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=anomaly_labels, cmap=plt.cm.Paired)\n",
    "        plt.title(\"Detecci√≥n de Anomal√≠as\")\n",
    "        plt.xlabel(\"Dimensi√≥n 1\")\n",
    "        plt.ylabel(\"Dimensi√≥n 2\")\n",
    "        plt.colorbar()\n",
    "        plt.savefig(os.path.join(anomalies_dir, \"anomalies_plot.pdf\"))\n",
    "        plt.close()\n",
    "        self.anomalies_data=anomalies_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def profile(self, columns=None, anomaly_threshold=0.05, top_n_categories=5, categorical_threshold=100, algoritmo=IsolationForest(contamination=0.05), cluster_algorithm=KMeans, n_clusters_range=range(2, 11)):\n",
    "        \"\"\"\n",
    "        Ejecuta todos los m√©todos anteriores en orden.\n",
    "\n",
    "        Par√°metros:\n",
    "        columns (list): Lista de nombres de las columnas a analizar en los m√©todos anteriores.\n",
    "        anomaly_threshold (float): Umbral para detectar anomal√≠as en porcentaje.\n",
    "        top_n_categories (int): N√∫mero de categor√≠as a mostrar en el histograma para variables categ√≥ricas.\n",
    "        categorical_threshold (int): Umbral para codificar variables categ√≥ricas en one-hot.\n",
    "        algorithm (str): El algoritmo de detecci√≥n de anomal√≠as a utilizar.\n",
    "        cluster_algorithm (sklearn.cluster.ClusterMixin): Algoritmo de clustering de scikit-learn.\n",
    "        n_clusters_range (range): Rango de valores para buscar el n√∫mero √≥ptimo de clusters.\n",
    "        \"\"\"\n",
    "        self.clean_data(columns=columns)\n",
    "        self.summarize(columns=columns, anomaly_threshold=anomaly_threshold)\n",
    "        self.plot_vars(columns=columns, top_n_categories=top_n_categories)\n",
    "        self.scale(categorical_threshold=categorical_threshold)\n",
    "        self.make_clusters(cluster_algorithm=cluster_algorithm, n_clusters_range=n_clusters_range)\n",
    "        self.detect_anomalies(algoritmo=algoritmo)\n",
    "\n",
    "\n",
    "    \n",
    "    def clearGarbage(self):\n",
    "        \"\"\"\n",
    "        Elimina las carpetas y archivos creados por la clase Profiler.\n",
    "        \"\"\"\n",
    "        if self.output_dir and os.path.exists(self.output_dir):\n",
    "            shutil.rmtree(self.output_dir)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathe\\Desktop\\2023-2\\LabMDS\\Proyecto1\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:143: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  num_cells = num_rows * num_columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al calcular la matriz de confusi√≥n para Name y age-height-weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kathe\\Desktop\\2023-2\\LabMDS\\Proyecto1\\.venv\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:143: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  num_cells = num_rows * num_columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al calcular la matriz de confusi√≥n para age-height-weight y Name\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kathe\\AppData\\Local\\Temp\\ipykernel_35196\\2632459414.py:394: UserWarning: The palette list has more values (4) than needed (3), which may not be intended.\n",
      "  sns.scatterplot(x='Dimension 1', y='Dimension 2', hue=reduced_data['Cluster'], data=reduced_data, palette=stgo2023)\n"
     ]
    }
   ],
   "source": [
    "perfil1 = Profiler('olimpiadas.parquet')\n",
    "perfil1.summarize()\n",
    "perfil1.plot_vars()\n",
    "perfil1.clean_data()\n",
    "perfil1.scale()\n",
    "perfil1.make_clusters()\n",
    "perfil1.detect_anomalies()\n",
    "# perfil1.clearGarbage()\n",
    "# perfil1.profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>ND</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>ND</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 1,000 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1992 Winter</td>\n",
       "      <td>1992</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albertville</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>ND</td>\n",
       "      <td>29.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>34.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206159 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      Name Sex         Team  NOC        Games  \\\n",
       "0            1                 A Dijiang   M        China  CHN  1992 Summer   \n",
       "1            2                  A Lamusi   M        China  CHN  2012 Summer   \n",
       "4            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "5            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "6            5  Christine Jacoba Aaftink   F  Netherlands  NED  1992 Winter   \n",
       "...        ...                       ...  ..          ...  ...          ...   \n",
       "271111  135569                Andrzej ya   M     Poland-1  POL  1976 Winter   \n",
       "271112  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271113  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271114  135571        Tomasz Ireneusz ya   M       Poland  POL  1998 Winter   \n",
       "271115  135571        Tomasz Ireneusz ya   M       Poland  POL  2002 Winter   \n",
       "\n",
       "        Year  Season            City          Sport  \\\n",
       "0       1992  Summer       Barcelona     Basketball   \n",
       "1       2012  Summer          London           Judo   \n",
       "4       1988  Winter         Calgary  Speed Skating   \n",
       "5       1988  Winter         Calgary  Speed Skating   \n",
       "6       1992  Winter     Albertville  Speed Skating   \n",
       "...      ...     ...             ...            ...   \n",
       "271111  1976  Winter       Innsbruck           Luge   \n",
       "271112  2014  Winter           Sochi    Ski Jumping   \n",
       "271113  2014  Winter           Sochi    Ski Jumping   \n",
       "271114  1998  Winter          Nagano      Bobsleigh   \n",
       "271115  2002  Winter  Salt Lake City      Bobsleigh   \n",
       "\n",
       "                                           Event Medal   age  height  weight  \n",
       "0                    Basketball Men's Basketball    ND  24.0   180.0    80.0  \n",
       "1                   Judo Men's Extra-Lightweight    ND  23.0   170.0    60.0  \n",
       "4               Speed Skating Women's 500 metres    ND  21.0   185.0    82.0  \n",
       "5             Speed Skating Women's 1,000 metres    ND  21.0   185.0    82.0  \n",
       "6               Speed Skating Women's 500 metres    ND  25.0   185.0    82.0  \n",
       "...                                          ...   ...   ...     ...     ...  \n",
       "271111                Luge Mixed (Men)'s Doubles    ND  29.0   179.0    89.0  \n",
       "271112  Ski Jumping Men's Large Hill, Individual    ND  27.0   176.0    59.0  \n",
       "271113        Ski Jumping Men's Large Hill, Team    ND  27.0   176.0    59.0  \n",
       "271114                      Bobsleigh Men's Four    ND  30.0   185.0    96.0  \n",
       "271115                      Bobsleigh Men's Four    ND  34.0   185.0    96.0  \n",
       "\n",
       "[206159 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfil1.cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Games_1896 Summer</th>\n",
       "      <th>Games_1900 Summer</th>\n",
       "      <th>Games_1904 Summer</th>\n",
       "      <th>...</th>\n",
       "      <th>Sport_Triathlon</th>\n",
       "      <th>Sport_Tug-Of-War</th>\n",
       "      <th>Sport_Volleyball</th>\n",
       "      <th>Sport_Water Polo</th>\n",
       "      <th>Sport_Weightlifting</th>\n",
       "      <th>Sport_Wrestling</th>\n",
       "      <th>Medal_Bronze</th>\n",
       "      <th>Medal_Gold</th>\n",
       "      <th>Medal_ND</th>\n",
       "      <th>Medal_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804847</td>\n",
       "      <td>0.409636</td>\n",
       "      <td>0.604739</td>\n",
       "      <td>0.537908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036449</td>\n",
       "      <td>0.967636</td>\n",
       "      <td>0.386853</td>\n",
       "      <td>0.505539</td>\n",
       "      <td>0.403674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.098760</td>\n",
       "      <td>0.772093</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.549454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098760</td>\n",
       "      <td>0.772093</td>\n",
       "      <td>0.338291</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.549454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098760</td>\n",
       "      <td>0.804847</td>\n",
       "      <td>0.431525</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.549454</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206154</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.673435</td>\n",
       "      <td>0.511392</td>\n",
       "      <td>0.595069</td>\n",
       "      <td>0.587782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206155</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.983826</td>\n",
       "      <td>0.472886</td>\n",
       "      <td>0.565733</td>\n",
       "      <td>0.395849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206156</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.983826</td>\n",
       "      <td>0.472886</td>\n",
       "      <td>0.565733</td>\n",
       "      <td>0.395849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206157</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853855</td>\n",
       "      <td>0.529692</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.623237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206158</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886445</td>\n",
       "      <td>0.597425</td>\n",
       "      <td>0.652301</td>\n",
       "      <td>0.623237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206159 rows √ó 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID      Year       age    height    weight  Sex_F  Sex_M  \\\n",
       "0       0.000000  0.804847  0.409636  0.604739  0.537908    0.0    1.0   \n",
       "1       0.036449  0.967636  0.386853  0.505539  0.403674    0.0    1.0   \n",
       "2       0.098760  0.772093  0.338291  0.652301  0.549454    1.0    0.0   \n",
       "3       0.098760  0.772093  0.338291  0.652301  0.549454    1.0    0.0   \n",
       "4       0.098760  0.804847  0.431525  0.652301  0.549454    1.0    0.0   \n",
       "...          ...       ...       ...       ...       ...    ...    ...   \n",
       "206154  0.999999  0.673435  0.511392  0.595069  0.587782    0.0    1.0   \n",
       "206155  0.999999  0.983826  0.472886  0.565733  0.395849    0.0    1.0   \n",
       "206156  0.999999  0.983826  0.472886  0.565733  0.395849    0.0    1.0   \n",
       "206157  1.000000  0.853855  0.529692  0.652301  0.623237    0.0    1.0   \n",
       "206158  1.000000  0.886445  0.597425  0.652301  0.623237    0.0    1.0   \n",
       "\n",
       "        Games_1896 Summer  Games_1900 Summer  Games_1904 Summer  ...  \\\n",
       "0                     0.0                0.0                0.0  ...   \n",
       "1                     0.0                0.0                0.0  ...   \n",
       "2                     0.0                0.0                0.0  ...   \n",
       "3                     0.0                0.0                0.0  ...   \n",
       "4                     0.0                0.0                0.0  ...   \n",
       "...                   ...                ...                ...  ...   \n",
       "206154                0.0                0.0                0.0  ...   \n",
       "206155                0.0                0.0                0.0  ...   \n",
       "206156                0.0                0.0                0.0  ...   \n",
       "206157                0.0                0.0                0.0  ...   \n",
       "206158                0.0                0.0                0.0  ...   \n",
       "\n",
       "        Sport_Triathlon  Sport_Tug-Of-War  Sport_Volleyball  Sport_Water Polo  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   0.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "206154              0.0               0.0               0.0               0.0   \n",
       "206155              0.0               0.0               0.0               0.0   \n",
       "206156              0.0               0.0               0.0               0.0   \n",
       "206157              0.0               0.0               0.0               0.0   \n",
       "206158              0.0               0.0               0.0               0.0   \n",
       "\n",
       "        Sport_Weightlifting  Sport_Wrestling  Medal_Bronze  Medal_Gold  \\\n",
       "0                       0.0              0.0           0.0         0.0   \n",
       "1                       0.0              0.0           0.0         0.0   \n",
       "2                       0.0              0.0           0.0         0.0   \n",
       "3                       0.0              0.0           0.0         0.0   \n",
       "4                       0.0              0.0           0.0         0.0   \n",
       "...                     ...              ...           ...         ...   \n",
       "206154                  0.0              0.0           0.0         0.0   \n",
       "206155                  0.0              0.0           0.0         0.0   \n",
       "206156                  0.0              0.0           0.0         0.0   \n",
       "206157                  0.0              0.0           0.0         0.0   \n",
       "206158                  0.0              0.0           0.0         0.0   \n",
       "\n",
       "        Medal_ND  Medal_Silver  \n",
       "0            1.0           0.0  \n",
       "1            1.0           0.0  \n",
       "2            1.0           0.0  \n",
       "3            1.0           0.0  \n",
       "4            1.0           0.0  \n",
       "...          ...           ...  \n",
       "206154       1.0           0.0  \n",
       "206155       1.0           0.0  \n",
       "206156       1.0           0.0  \n",
       "206157       1.0           0.0  \n",
       "206158       1.0           0.0  \n",
       "\n",
       "[206159 rows x 162 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfil1.scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>ND</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>ND</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 1,000 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1992 Winter</td>\n",
       "      <td>1992</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albertville</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>ND</td>\n",
       "      <td>29.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>34.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206159 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      Name Sex         Team  NOC        Games  \\\n",
       "0            1                 A Dijiang   M        China  CHN  1992 Summer   \n",
       "1            2                  A Lamusi   M        China  CHN  2012 Summer   \n",
       "4            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "5            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "6            5  Christine Jacoba Aaftink   F  Netherlands  NED  1992 Winter   \n",
       "...        ...                       ...  ..          ...  ...          ...   \n",
       "271111  135569                Andrzej ya   M     Poland-1  POL  1976 Winter   \n",
       "271112  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271113  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271114  135571        Tomasz Ireneusz ya   M       Poland  POL  1998 Winter   \n",
       "271115  135571        Tomasz Ireneusz ya   M       Poland  POL  2002 Winter   \n",
       "\n",
       "        Year  Season            City          Sport  \\\n",
       "0       1992  Summer       Barcelona     Basketball   \n",
       "1       2012  Summer          London           Judo   \n",
       "4       1988  Winter         Calgary  Speed Skating   \n",
       "5       1988  Winter         Calgary  Speed Skating   \n",
       "6       1992  Winter     Albertville  Speed Skating   \n",
       "...      ...     ...             ...            ...   \n",
       "271111  1976  Winter       Innsbruck           Luge   \n",
       "271112  2014  Winter           Sochi    Ski Jumping   \n",
       "271113  2014  Winter           Sochi    Ski Jumping   \n",
       "271114  1998  Winter          Nagano      Bobsleigh   \n",
       "271115  2002  Winter  Salt Lake City      Bobsleigh   \n",
       "\n",
       "                                           Event Medal   age  height  weight  \\\n",
       "0                    Basketball Men's Basketball    ND  24.0   180.0    80.0   \n",
       "1                   Judo Men's Extra-Lightweight    ND  23.0   170.0    60.0   \n",
       "4               Speed Skating Women's 500 metres    ND  21.0   185.0    82.0   \n",
       "5             Speed Skating Women's 1,000 metres    ND  21.0   185.0    82.0   \n",
       "6               Speed Skating Women's 500 metres    ND  25.0   185.0    82.0   \n",
       "...                                          ...   ...   ...     ...     ...   \n",
       "271111                Luge Mixed (Men)'s Doubles    ND  29.0   179.0    89.0   \n",
       "271112  Ski Jumping Men's Large Hill, Individual    ND  27.0   176.0    59.0   \n",
       "271113        Ski Jumping Men's Large Hill, Team    ND  27.0   176.0    59.0   \n",
       "271114                      Bobsleigh Men's Four    ND  30.0   185.0    96.0   \n",
       "271115                      Bobsleigh Men's Four    ND  34.0   185.0    96.0   \n",
       "\n",
       "        Cluster  \n",
       "0             0  \n",
       "1             0  \n",
       "4             2  \n",
       "5             2  \n",
       "6             2  \n",
       "...         ...  \n",
       "271111        2  \n",
       "271112        2  \n",
       "271113        2  \n",
       "271114        2  \n",
       "271115        2  \n",
       "\n",
       "[206159 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfil1.cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los datos por el valor de la columna 'Cluster'\n",
    "cluster_groups = perfil1.cluster_data.groupby('Cluster')\n",
    "\n",
    "# Calcular estad√≠sticas descriptivas para cada cluster\n",
    "cluster_summaries = []\n",
    "for cluster, cluster_data in cluster_groups:\n",
    "    cluster_summary = cluster_data.describe(include=\"all\")\n",
    "    cluster_summary['Cluster'] = cluster  # Agregar el n√∫mero de cluster como una columna\n",
    "    cluster_summaries.append(cluster_summary)\n",
    "\n",
    "# Concatenar los res√∫menes de cada cluster en un solo DataFrame\n",
    "cluster_summary_df = pd.concat(cluster_summaries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = perfil1.cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>113319.000000</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319.000000</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319</td>\n",
       "      <td>113319.000000</td>\n",
       "      <td>113319.000000</td>\n",
       "      <td>113319.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>59201</td>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>225</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>322</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heikki Ilmari Savolainen</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>2000 Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Athletics</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>113319</td>\n",
       "      <td>7083</td>\n",
       "      <td>7187</td>\n",
       "      <td>8296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113319</td>\n",
       "      <td>8296</td>\n",
       "      <td>21391</td>\n",
       "      <td>3459</td>\n",
       "      <td>96643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67556.802637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.475957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.699600</td>\n",
       "      <td>179.017182</td>\n",
       "      <td>75.657802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39142.905071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.672749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.507685</td>\n",
       "      <td>9.901566</td>\n",
       "      <td>13.755274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1896.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33688.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67595.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101501.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135567.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                      Name     Sex           Team  \\\n",
       "count   113319.000000                    113319  113319         113319   \n",
       "unique            NaN                     59201       1            588   \n",
       "top               NaN  Heikki Ilmari Savolainen       M  United States   \n",
       "freq              NaN                        39  113319           7083   \n",
       "mean     67556.802637                       NaN     NaN            NaN   \n",
       "std      39142.905071                       NaN     NaN            NaN   \n",
       "min          1.000000                       NaN     NaN            NaN   \n",
       "25%      33688.000000                       NaN     NaN            NaN   \n",
       "50%      67595.000000                       NaN     NaN            NaN   \n",
       "75%     101501.000000                       NaN     NaN            NaN   \n",
       "max     135567.000000                       NaN     NaN            NaN   \n",
       "\n",
       "           NOC        Games           Year  Season    City      Sport  \\\n",
       "count   113319       113319  113319.000000  113319  113319     113319   \n",
       "unique     225           29            NaN       1      23         40   \n",
       "top        USA  2000 Summer            NaN  Summer  Sydney  Athletics   \n",
       "freq      7187         8296            NaN  113319    8296      21391   \n",
       "mean       NaN          NaN    1985.475957     NaN     NaN        NaN   \n",
       "std        NaN          NaN      21.672749     NaN     NaN        NaN   \n",
       "min        NaN          NaN    1896.000000     NaN     NaN        NaN   \n",
       "25%        NaN          NaN    1972.000000     NaN     NaN        NaN   \n",
       "50%        NaN          NaN    1988.000000     NaN     NaN        NaN   \n",
       "75%        NaN          NaN    2004.000000     NaN     NaN        NaN   \n",
       "max        NaN          NaN    2016.000000     NaN     NaN        NaN   \n",
       "\n",
       "                          Event   Medal            age         height  \\\n",
       "count                    113319  113319  113319.000000  113319.000000   \n",
       "unique                      322       4            NaN            NaN   \n",
       "top     Football Men's Football      ND            NaN            NaN   \n",
       "freq                       3459   96643            NaN            NaN   \n",
       "mean                        NaN     NaN      25.699600     179.017182   \n",
       "std                         NaN     NaN       5.507685       9.901566   \n",
       "min                         NaN     NaN      12.000000     127.000000   \n",
       "25%                         NaN     NaN      22.000000     172.000000   \n",
       "50%                         NaN     NaN      25.000000     179.000000   \n",
       "75%                         NaN     NaN      28.000000     185.000000   \n",
       "max                         NaN     NaN      71.000000     226.000000   \n",
       "\n",
       "               weight  Cluster  \n",
       "count   113319.000000        0  \n",
       "unique            NaN        0  \n",
       "top               NaN        0  \n",
       "freq              NaN        0  \n",
       "mean        75.657802        0  \n",
       "std         13.755274        0  \n",
       "min         28.000000        0  \n",
       "25%         66.000000        0  \n",
       "50%         74.000000        0  \n",
       "75%         83.000000        0  \n",
       "max        214.000000        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cluster_summary_df[cluster_summary_df['Cluster']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medal\n",
      "ND        96643\n",
      "Gold       5667\n",
      "Bronze     5646\n",
      "Silver     5363\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas donde \"Cluster\" es igual a 0\n",
    "cluster_0_df = cluster_df[cluster_df[\"Cluster\"] == 0]\n",
    "\n",
    "# Contar la frecuencia de valores √∫nicos en la columna \"Medal\"\n",
    "medal_counts = cluster_0_df[\"Medal\"].value_counts()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(medal_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53381.000000</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381.000000</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381</td>\n",
       "      <td>53381.000000</td>\n",
       "      <td>53381.000000</td>\n",
       "      <td>53381.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25446</td>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>218</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>171</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Oksana Aleksandrovna Chusovitina</td>\n",
       "      <td>F</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016 Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Athletics</td>\n",
       "      <td>Volleyball Women's Volleyball</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>53381</td>\n",
       "      <td>3747</td>\n",
       "      <td>3798</td>\n",
       "      <td>6121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53381</td>\n",
       "      <td>6121</td>\n",
       "      <td>10983</td>\n",
       "      <td>1495</td>\n",
       "      <td>44716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69830.691164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.278620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.653098</td>\n",
       "      <td>168.184129</td>\n",
       "      <td>60.089217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39044.212524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.976362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.741069</td>\n",
       "      <td>9.299868</td>\n",
       "      <td>10.851675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35974.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70481.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103325.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135568.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                              Name    Sex           Team  \\\n",
       "count    53381.000000                             53381  53381          53381   \n",
       "unique            NaN                             25446      1            314   \n",
       "top               NaN  Oksana Aleksandrovna Chusovitina      F  United States   \n",
       "freq              NaN                                29  53381           3747   \n",
       "mean     69830.691164                               NaN    NaN            NaN   \n",
       "std      39044.212524                               NaN    NaN            NaN   \n",
       "min         13.000000                               NaN    NaN            NaN   \n",
       "25%      35974.000000                               NaN    NaN            NaN   \n",
       "50%      70481.000000                               NaN    NaN            NaN   \n",
       "75%     103325.000000                               NaN    NaN            NaN   \n",
       "max     135568.000000                               NaN    NaN            NaN   \n",
       "\n",
       "          NOC        Games          Year  Season            City      Sport  \\\n",
       "count   53381        53381  53381.000000   53381           53381      53381   \n",
       "unique    218           23           NaN       1              22         36   \n",
       "top       USA  2016 Summer           NaN  Summer  Rio de Janeiro  Athletics   \n",
       "freq     3798         6121           NaN   53381            6121      10983   \n",
       "mean      NaN          NaN   1995.278620     NaN             NaN        NaN   \n",
       "std       NaN          NaN     16.976362     NaN             NaN        NaN   \n",
       "min       NaN          NaN   1920.000000     NaN             NaN        NaN   \n",
       "25%       NaN          NaN   1984.000000     NaN             NaN        NaN   \n",
       "50%       NaN          NaN   2000.000000     NaN             NaN        NaN   \n",
       "75%       NaN          NaN   2008.000000     NaN             NaN        NaN   \n",
       "max       NaN          NaN   2016.000000     NaN             NaN        NaN   \n",
       "\n",
       "                                Event  Medal           age        height  \\\n",
       "count                           53381  53381  53381.000000  53381.000000   \n",
       "unique                            171      4           NaN           NaN   \n",
       "top     Volleyball Women's Volleyball     ND           NaN           NaN   \n",
       "freq                             1495  44716           NaN           NaN   \n",
       "mean                              NaN    NaN     23.653098    168.184129   \n",
       "std                               NaN    NaN      5.741069      9.299868   \n",
       "min                               NaN    NaN     11.000000    127.000000   \n",
       "25%                               NaN    NaN     19.000000    162.000000   \n",
       "50%                               NaN    NaN     23.000000    168.000000   \n",
       "75%                               NaN    NaN     27.000000    174.000000   \n",
       "max                               NaN    NaN     69.000000    213.000000   \n",
       "\n",
       "              weight  Cluster  \n",
       "count   53381.000000        1  \n",
       "unique           NaN        1  \n",
       "top              NaN        1  \n",
       "freq             NaN        1  \n",
       "mean       60.089217        1  \n",
       "std        10.851675        1  \n",
       "min        25.000000        1  \n",
       "25%        53.000000        1  \n",
       "50%        59.000000        1  \n",
       "75%        66.000000        1  \n",
       "max       167.000000        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cluster_summary_df[cluster_summary_df['Cluster']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medal\n",
      "ND        44716\n",
      "Bronze     2920\n",
      "Gold       2875\n",
      "Silver     2870\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas donde \"Cluster\" es igual a 1\n",
    "cluster_1_df = cluster_df[cluster_df[\"Cluster\"] == 1]\n",
    "\n",
    "# Contar la frecuencia de valores √∫nicos en la columna \"Medal\"\n",
    "medal_counts = cluster_1_df[\"Medal\"].value_counts()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(medal_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39459.000000</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459.000000</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459</td>\n",
       "      <td>39459.000000</td>\n",
       "      <td>39459.000000</td>\n",
       "      <td>39459.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14118</td>\n",
       "      <td>2</td>\n",
       "      <td>208</td>\n",
       "      <td>114</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Ole Einar Bjrndalen</td>\n",
       "      <td>M</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Cross Country Skiing</td>\n",
       "      <td>Ice Hockey Men's Ice Hockey</td>\n",
       "      <td>ND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>26129</td>\n",
       "      <td>2881</td>\n",
       "      <td>3226</td>\n",
       "      <td>4673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39459</td>\n",
       "      <td>4673</td>\n",
       "      <td>7529</td>\n",
       "      <td>3807</td>\n",
       "      <td>34619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70014.100231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994.161079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.101447</td>\n",
       "      <td>174.627360</td>\n",
       "      <td>70.755417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38416.833052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.270254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.635869</td>\n",
       "      <td>8.597311</td>\n",
       "      <td>12.201170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1924.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38306.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68415.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>103757.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>135571.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID                 Name    Sex           Team    NOC  \\\n",
       "count    39459.000000                39459  39459          39459  39459   \n",
       "unique            NaN                14118      2            208    114   \n",
       "top               NaN  Ole Einar Bjrndalen      M  United States    USA   \n",
       "freq              NaN                   27  26129           2881   3226   \n",
       "mean     70014.100231                  NaN    NaN            NaN    NaN   \n",
       "std      38416.833052                  NaN    NaN            NaN    NaN   \n",
       "min          5.000000                  NaN    NaN            NaN    NaN   \n",
       "25%      38306.000000                  NaN    NaN            NaN    NaN   \n",
       "50%      68415.000000                  NaN    NaN            NaN    NaN   \n",
       "75%     103757.000000                  NaN    NaN            NaN    NaN   \n",
       "max     135571.000000                  NaN    NaN            NaN    NaN   \n",
       "\n",
       "              Games          Year  Season   City                 Sport  \\\n",
       "count         39459  39459.000000   39459  39459                 39459   \n",
       "unique           22           NaN       1     19                    15   \n",
       "top     2014 Winter           NaN  Winter  Sochi  Cross Country Skiing   \n",
       "freq           4673           NaN   39459   4673                  7529   \n",
       "mean            NaN   1994.161079     NaN    NaN                   NaN   \n",
       "std             NaN     16.270254     NaN    NaN                   NaN   \n",
       "min             NaN   1924.000000     NaN    NaN                   NaN   \n",
       "25%             NaN   1984.000000     NaN    NaN                   NaN   \n",
       "50%             NaN   1998.000000     NaN    NaN                   NaN   \n",
       "75%             NaN   2006.000000     NaN    NaN                   NaN   \n",
       "max             NaN   2014.000000     NaN    NaN                   NaN   \n",
       "\n",
       "                              Event  Medal           age        height  \\\n",
       "count                         39459  39459  39459.000000  39459.000000   \n",
       "unique                          117      4           NaN           NaN   \n",
       "top     Ice Hockey Men's Ice Hockey     ND           NaN           NaN   \n",
       "freq                           3807  34619           NaN           NaN   \n",
       "mean                            NaN    NaN     25.101447    174.627360   \n",
       "std                             NaN    NaN      4.635869      8.597311   \n",
       "min                             NaN    NaN     11.000000    137.000000   \n",
       "25%                             NaN    NaN     22.000000    168.000000   \n",
       "50%                             NaN    NaN     25.000000    175.000000   \n",
       "75%                             NaN    NaN     28.000000    181.000000   \n",
       "max                             NaN    NaN     55.000000    206.000000   \n",
       "\n",
       "              weight  Cluster  \n",
       "count   39459.000000        2  \n",
       "unique           NaN        2  \n",
       "top              NaN        2  \n",
       "freq             NaN        2  \n",
       "mean       70.755417        2  \n",
       "std        12.201170        2  \n",
       "min        32.000000        2  \n",
       "25%        62.000000        2  \n",
       "50%        70.000000        2  \n",
       "75%        79.000000        2  \n",
       "max       145.000000        2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cluster_summary_df[cluster_summary_df['Cluster']==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medal\n",
      "ND        34619\n",
      "Silver     1633\n",
      "Gold       1625\n",
      "Bronze     1582\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para obtener solo las filas donde \"Cluster\" es igual a 2\n",
    "cluster_2_df = cluster_df[cluster_df[\"Cluster\"] == 2]\n",
    "\n",
    "# Contar la frecuencia de valores √∫nicos en la columna \"Medal\"\n",
    "medal_counts = cluster_2_df[\"Medal\"].value_counts()\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(medal_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>anomaly_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>ND</td>\n",
       "      <td>24.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>ND</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 1,000 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>21.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1992 Winter</td>\n",
       "      <td>1992</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Albertville</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>ND</td>\n",
       "      <td>25.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>ND</td>\n",
       "      <td>29.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>ND</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>30.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>ND</td>\n",
       "      <td>34.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206159 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      Name Sex         Team  NOC        Games  \\\n",
       "0            1                 A Dijiang   M        China  CHN  1992 Summer   \n",
       "1            2                  A Lamusi   M        China  CHN  2012 Summer   \n",
       "4            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "5            5  Christine Jacoba Aaftink   F  Netherlands  NED  1988 Winter   \n",
       "6            5  Christine Jacoba Aaftink   F  Netherlands  NED  1992 Winter   \n",
       "...        ...                       ...  ..          ...  ...          ...   \n",
       "271111  135569                Andrzej ya   M     Poland-1  POL  1976 Winter   \n",
       "271112  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271113  135570                  Piotr ya   M       Poland  POL  2014 Winter   \n",
       "271114  135571        Tomasz Ireneusz ya   M       Poland  POL  1998 Winter   \n",
       "271115  135571        Tomasz Ireneusz ya   M       Poland  POL  2002 Winter   \n",
       "\n",
       "        Year  Season            City          Sport  \\\n",
       "0       1992  Summer       Barcelona     Basketball   \n",
       "1       2012  Summer          London           Judo   \n",
       "4       1988  Winter         Calgary  Speed Skating   \n",
       "5       1988  Winter         Calgary  Speed Skating   \n",
       "6       1992  Winter     Albertville  Speed Skating   \n",
       "...      ...     ...             ...            ...   \n",
       "271111  1976  Winter       Innsbruck           Luge   \n",
       "271112  2014  Winter           Sochi    Ski Jumping   \n",
       "271113  2014  Winter           Sochi    Ski Jumping   \n",
       "271114  1998  Winter          Nagano      Bobsleigh   \n",
       "271115  2002  Winter  Salt Lake City      Bobsleigh   \n",
       "\n",
       "                                           Event Medal   age  height  weight  \\\n",
       "0                    Basketball Men's Basketball    ND  24.0   180.0    80.0   \n",
       "1                   Judo Men's Extra-Lightweight    ND  23.0   170.0    60.0   \n",
       "4               Speed Skating Women's 500 metres    ND  21.0   185.0    82.0   \n",
       "5             Speed Skating Women's 1,000 metres    ND  21.0   185.0    82.0   \n",
       "6               Speed Skating Women's 500 metres    ND  25.0   185.0    82.0   \n",
       "...                                          ...   ...   ...     ...     ...   \n",
       "271111                Luge Mixed (Men)'s Doubles    ND  29.0   179.0    89.0   \n",
       "271112  Ski Jumping Men's Large Hill, Individual    ND  27.0   176.0    59.0   \n",
       "271113        Ski Jumping Men's Large Hill, Team    ND  27.0   176.0    59.0   \n",
       "271114                      Bobsleigh Men's Four    ND  30.0   185.0    96.0   \n",
       "271115                      Bobsleigh Men's Four    ND  34.0   185.0    96.0   \n",
       "\n",
       "        anomaly_labels  \n",
       "0                    1  \n",
       "1                    1  \n",
       "4                    1  \n",
       "5                    1  \n",
       "6                    1  \n",
       "...                ...  \n",
       "271111               1  \n",
       "271112               1  \n",
       "271113               1  \n",
       "271114              -1  \n",
       "271115              -1  \n",
       "\n",
       "[206159 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfil1.anomalies_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def summary_of_anomalies(dataframe):\n",
    "    # Filtrar las instancias normales y an√≥malas\n",
    "    normal_instances = dataframe[dataframe['anomaly_labels'] == 1]\n",
    "    anomaly_instances = dataframe[dataframe['anomaly_labels'] == -1]\n",
    "\n",
    "    # Resumen de las instancias normales\n",
    "    normal_summary = normal_instances.describe(include=\"all\")\n",
    "\n",
    "    # Resumen de las instancias an√≥malas\n",
    "    anomaly_summary = anomaly_instances.describe(include=\"all\")\n",
    "\n",
    "    return normal_summary, anomaly_summary\n",
    "\n",
    "# Llamar a la funci√≥n con tu DataFrame\n",
    "normal_summary, anomaly_summary = summary_of_anomalies(perfil1.anomalies_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de instancias normales:\n",
      "                   ID                      Name     Sex           Team  \\\n",
      "count   195853.000000                    195853  195853         195853   \n",
      "unique            NaN                     95760       2            629   \n",
      "top               NaN  Heikki Ilmari Savolainen       M  United States   \n",
      "freq              NaN                        39  133691          12706   \n",
      "mean     68540.717508                       NaN     NaN            NaN   \n",
      "std      38939.893946                       NaN     NaN            NaN   \n",
      "min          1.000000                       NaN     NaN            NaN   \n",
      "25%      35139.000000                       NaN     NaN            NaN   \n",
      "50%      68613.000000                       NaN     NaN            NaN   \n",
      "75%     102113.000000                       NaN     NaN            NaN   \n",
      "max     135570.000000                       NaN     NaN            NaN   \n",
      "\n",
      "           NOC        Games           Year  Season    City      Sport  \\\n",
      "count   195853       195853  195853.000000  195853  195853     195853   \n",
      "unique     226           51            NaN       2      42         56   \n",
      "top        USA  2000 Summer            NaN  Summer  Sydney  Athletics   \n",
      "freq     13052        13668            NaN  163902   13668      32152   \n",
      "mean       NaN          NaN    1989.731125     NaN     NaN        NaN   \n",
      "std        NaN          NaN      20.264963     NaN     NaN        NaN   \n",
      "min        NaN          NaN    1896.000000     NaN     NaN        NaN   \n",
      "25%        NaN          NaN    1976.000000     NaN     NaN        NaN   \n",
      "50%        NaN          NaN    1992.000000     NaN     NaN        NaN   \n",
      "75%        NaN          NaN    2006.000000     NaN     NaN        NaN   \n",
      "max        NaN          NaN    2016.000000     NaN     NaN        NaN   \n",
      "\n",
      "                          Event   Medal            age         height  \\\n",
      "count                    195853  195853  195853.000000  195853.000000   \n",
      "unique                      590       4            NaN            NaN   \n",
      "top     Football Men's Football      ND            NaN            NaN   \n",
      "freq                       3442  171669            NaN            NaN   \n",
      "mean                        NaN     NaN      25.033382     175.435786   \n",
      "std                         NaN     NaN       5.476732      10.516533   \n",
      "min                         NaN     NaN      11.000000     127.000000   \n",
      "25%                         NaN     NaN      21.000000     168.000000   \n",
      "50%                         NaN     NaN      24.000000     175.000000   \n",
      "75%                         NaN     NaN      28.000000     183.000000   \n",
      "max                         NaN     NaN      71.000000     226.000000   \n",
      "\n",
      "               weight  anomaly_labels  \n",
      "count   195853.000000        195853.0  \n",
      "unique            NaN             NaN  \n",
      "top               NaN             NaN  \n",
      "freq              NaN             NaN  \n",
      "mean        70.633115             1.0  \n",
      "std         14.216414             0.0  \n",
      "min         25.000000             1.0  \n",
      "25%         60.000000             1.0  \n",
      "50%         70.000000             1.0  \n",
      "75%         79.000000             1.0  \n",
      "max        214.000000             1.0  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar los res√∫menes\n",
    "print(\"Resumen de instancias normales:\")\n",
    "print(normal_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen de instancias an√≥malas:\n",
      "                   ID       Name    Sex           Team    NOC        Games  \\\n",
      "count    10306.000000      10306  10306          10306  10306        10306   \n",
      "unique            NaN       6748      2            205     94           40   \n",
      "top               NaN  Yang Yang      M  United States    USA  1998 Winter   \n",
      "freq              NaN         16   5757           1005   1159         2012   \n",
      "mean     70044.894042        NaN    NaN            NaN    NaN          NaN   \n",
      "std      40037.539434        NaN    NaN            NaN    NaN          NaN   \n",
      "min         16.000000        NaN    NaN            NaN    NaN          NaN   \n",
      "25%      36046.000000        NaN    NaN            NaN    NaN          NaN   \n",
      "50%      69250.500000        NaN    NaN            NaN    NaN          NaN   \n",
      "75%     105974.000000        NaN    NaN            NaN    NaN          NaN   \n",
      "max     135571.000000        NaN    NaN            NaN    NaN          NaN   \n",
      "\n",
      "                Year  Season    City       Sport                        Event  \\\n",
      "count   10306.000000   10306   10306       10306                        10306   \n",
      "unique           NaN       2      37          44                          362   \n",
      "top              NaN  Winter  Nagano  Ice Hockey  Ice Hockey Men's Ice Hockey   \n",
      "freq             NaN    7508    2012        1491                         1076   \n",
      "mean     1988.638657     NaN     NaN         NaN                          NaN   \n",
      "std        17.294033     NaN     NaN         NaN                          NaN   \n",
      "min      1908.000000     NaN     NaN         NaN                          NaN   \n",
      "25%      1972.000000     NaN     NaN         NaN                          NaN   \n",
      "50%      1992.000000     NaN     NaN         NaN                          NaN   \n",
      "75%      2002.000000     NaN     NaN         NaN                          NaN   \n",
      "max      2016.000000     NaN     NaN         NaN                          NaN   \n",
      "\n",
      "        Medal           age        height        weight  anomaly_labels  \n",
      "count   10306  10306.000000  10306.000000  10306.000000         10306.0  \n",
      "unique      4           NaN           NaN           NaN             NaN  \n",
      "top        ND           NaN           NaN           NaN             NaN  \n",
      "freq     4309           NaN           NaN           NaN             NaN  \n",
      "mean      NaN     25.470017    174.158840     71.736804            -1.0  \n",
      "std       NaN      5.577466     11.021795     16.487601             0.0  \n",
      "min       NaN     11.000000    136.000000     28.000000            -1.0  \n",
      "25%       NaN     22.000000    166.000000     59.000000            -1.0  \n",
      "50%       NaN     25.000000    174.000000     70.000000            -1.0  \n",
      "75%       NaN     28.000000    182.000000     82.000000            -1.0  \n",
      "max       NaN     63.000000    223.000000    163.000000            -1.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResumen de instancias an√≥malas:\")\n",
    "print(anomaly_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Caracterizar datos de Olimpiadas (2.0 puntos)\n",
    "\n",
    "A partir de la clase que hemos desarrollado previamente, procederemos a realizar un an√°lisis exhaustivo de los datos proporcionados en el enunciado. Este an√°lisis se presentar√° en forma de un informe contenido en el mismo Jupyter Notebook y abordar√° los siguientes puntos:\n",
    "\n",
    "1. Introducci√≥n\n",
    "    - Se proporcionar√° una breve descripci√≥n del problema que estamos abordando y se explicar√° la metodolog√≠a que se seguir√°.\n",
    "\n",
    "Elaborar una breve introducci√≥n con todo lo necesario para entender qu√© realizar√°n durante su proyecto. La idea es que describan de manera formal el proyecto con sus propias palabras y logren describir algunos aspectos b√°sicos tanto del dataset como del an√°lisis a realizar sobre los datos.\n",
    "\n",
    "Por lo anterior, en esta secci√≥n ustedes deber√°n ser capaces de:\n",
    "\n",
    "- Describir la tarea asociada al dataset.\n",
    "- Describir brevemente los datos de entrada que les provee el problema.\n",
    "- Plantear hip√≥tesis de c√≥mo podr√≠an abordar el problema.\n",
    "\n",
    "2. An√°lisis del EDA (An√°lisis Exploratorio de Datos)\n",
    "    - Se discutir√°n las observaciones y conclusiones obtenidas acerca de los datos proporcionados. A lo largo de su respuesta, debe responder preguntas como:\n",
    "        - ¬øComo se comportan las variables num√©ricas? ¬øy las categ√≥ricas?\n",
    "        - ¬øExisten valores nulos en el dataset? ¬øEn qu√© columnas? ¬øCuantos?\n",
    "        - ¬øCu√°les son las categor√≠as y frecuencias de las variables categ√≥ricas?\n",
    "        - ¬øExisten datos duplicados en el conjunto?\n",
    "        - ¬øExisten relaciones o patrones visuales entre las variables?\n",
    "        - ¬øExisten anomal√≠as notables o preocupantes en los datos?\n",
    "3. Creaci√≥n de Clusters y Anomal√≠as\n",
    "    - Se justificar√° la elecci√≥n de los algoritmos a utilizar y sus hiperpar√°metros. En el caso de clustering, justifique adem√°s el n√∫mero de clusters.\n",
    "    \n",
    "4. An√°lisis de Resultados\n",
    "    - Se examinar√°n los resultados obtenidos a partir de los cl√∫sters y anomal√≠as generadas. ¬øSe logra una separaci√≥n efectiva de los datos? Entregue una interpretaci√≥n de lo que representa cada cl√∫ster y anomal√≠a.\n",
    "5. Conclusi√≥n\n",
    "    - Se resumir√°n las principales conclusiones del an√°lisis y se destacar√°n las implicaciones pr√°cticas de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Introducci√≥n**\n",
    "La tarea desarrollada se centra en poder caracterizar de forma autom√°tica los datos obtenidos de los Juegos de Santiago 2023, para esto se solicita desarrollar una clase que pueda cumplir con dicha tarea para cualquier tipo de dataset, la clase en particular debe ser capaz de generar un resumen de los datos obtenidos, as√≠ como aplicar una limpieza de los datos  y un escalamiento de estos para su posterior uso, adem√°s se espera generar una cantidad √≥ptima de Clusters para segmentar a los distintos atletas que participen en dichos juegos y detectar anomal√≠as dentro de los datos. Para la creaci√≥n de esta clase y a modo de ejemplo se utiliza un dataset llamado Olimpiadas que contiene informaci√≥n de los distintos atletas que han participado en los distintos juegos olimpicos que se han realizado desde el a√±o 1896 hasta el 2016, este periodo abarca 51 de estos juegos, la informaci√≥n de los datos abarca el nombre, pa√≠s, a√±o de competencia, juego ol√≠mpico en el que particip√≥, deporte, medalla ganada, entre otros.\n",
    "\n",
    "#### **An√°lisis exploratorio de datos**\n",
    "El dataset cuenta con 2 variables num√©ricas: 'ID' y 'Year', Adem√°s cuenta con 11 variables categ√≥ricas: 'Name', 'Sex', 'Team', 'NOC', 'Games', 'Season', 'City', 'Sport', 'Event', 'Medal', 'age-height-weight'. a continuaci√≥n se describe cada una de estas variables, para las variables categ√≥ricas tambi√©n se muestran la frecuencia de las categor√≠as, en caso de poseer mas de 5 categor√≠as se presentan las 5 con mayor frecuencia:\n",
    "   - ID: Presenta un ID √∫nico para cada atleta\n",
    "   - Year: Presenta el a√±o en el que fueron realizados los juegos\n",
    "   - Name: Corresponde al nombre del atleta\n",
    "      - Robert Tait McKenzie: 58\n",
    "      - Heikki Ilmari Savolainen: 39\n",
    "      - Joseph \"Josy\" Stoffel: 38\n",
    "      - Ioannis Theofilakis: 36\n",
    "      - Takashi Ono: 33\n",
    "   - Sex: Corresponde al genero del atleta (F o M)\n",
    "      - M: 196.594\n",
    "      - F: 74.522\n",
    "   - Team: Equipo al que pertenece el atleta (en general es el pa√≠s por el que participa)\n",
    "      - United States: 17.847\n",
    "      - France: 11.988\n",
    "      - Great Britain: 11.404\n",
    "      - Italy: 10.260\n",
    "      - Germany: 9.326\n",
    "   - NOC: Abreviatura de 3 letras para el Team\n",
    "      - USA: 18.853\n",
    "      - FRA: 12.758\n",
    "      - GBR: 12.256\n",
    "      - ITA: 10.715\n",
    "      - GER: 9.830\n",
    "   - Games: A√±o y nombre del juego ol√≠mpico\n",
    "      - 2000 Summer: 13.821\n",
    "      - 1996 Summer: 13.780\n",
    "      - 2016 Summer: 13.688\n",
    "      - 2008 Summer: 13.602\n",
    "      - 2004 Summer: 13.443\n",
    "   - Season: Estaci√≥n del a√±o en el que se realizaron los juegos\n",
    "      - Summer: 222.552\n",
    "      - Winter: 48.564\n",
    "   - City: Ciudad donde se realiz√≥ el evento deportivo en el que particip√≥ el atleta\n",
    "      - London: 22.426\n",
    "      - Athina: 15.556\n",
    "      - Sydney: 13.821\n",
    "      - Atlanta: 13.780\n",
    "      - Rio de Janeiro: 13.688\n",
    "   - Sport: Deporte en el que particip√≥ el atleta\n",
    "      - Athletics: 38.624\n",
    "      - Gymnastics: 26.707\n",
    "      - Swimming: 23.195\n",
    "      - Shooting: 11.448\n",
    "      - Cycling: 10.859\n",
    "   - Event: Evento en el que particip√≥ el atleta, especifica la modalidad del deporte de la competencia\n",
    "      - Football Men's Football: 5.733\n",
    "      - Ice Hockey Men's Ice Hockey: 4.762\n",
    "      - Hockey Men's Hockey: 3.958\n",
    "      - Water Polo Men's Water Polo: 3.358\n",
    "      - Basketball Men's Basketball: 3.280\n",
    "   - Medal: Presenta la medalla ganada por el atleta (Gold, Silver y Bronze), en caso de no haber ganado una medalla se presenta con NA\n",
    "      - Gold: 13.372\n",
    "      - Bronze: 13.295\n",
    "      - Silver: 13.116\n",
    "   - age-height-weight: Variable no at√≥mica que presenta la edad, la altura y el peso del atleta\n",
    "\n",
    "   En cuanto a los valores nulos estos solo se presentan en la variable 'Medal', esta variable cuenta con 231.333 valores nulos, lo que se√±ala que la mayor√≠a de atletas no logr√≥ ganar una medalla. las variables categ√≥ricas presentan un rango significativo en cuanto a la cantidad de categor√≠as que presentan, siendo 'sex' la variable con menos categor√≠as presentando solo 2 (M y F), mientras que la variable 'Name' es la que presenta una mayor cantidad de categor√≠as con 134.732 (Cada nombre de atleta es una categor√≠a). Se presentan datos duplicados en ambas variables n√∫mericas, en caso de ID presenta 135.545 datos duplicados y Year presenta 271.081, esto tiene sentido ya que el ID est√° asociado a cada atleta y los atletas generalmente participan en mas de un juego ol√≠mpico y en mas de una competencia, adem√°s la columna Year repetir√° su valor por cada competencia y atleta que particip√≥ en esta en un juego en particular. En cuanto a las relaciones entre variables, para las n√∫mericas se tiene una correlaci√≥n de 0.012 entre ID y Year, lo cual no presenta una correlaci√≥n significativa. Para las variables categ√≥ricas se utiliz√≥ el coeficiente V de Cramer para analizar las relaciones, los resultados de estas muestran una relaci√≥n significativa entre variables que identifican al atleta como Name y age-height-weight, y en las variables que identifican los juegos como: Game, City y season. Luego una de las relaciones interesantes que se observan es la relaci√≥n entre Medals y age-height-weight que presenta un alto coeficiente de Cramer, por otro lado la variable Medal no presenta alguna otra relaci√≥n relevante. Por √∫ltimo la principal anomal√≠a observada es en la variable age-height-weight tanto por ser una variable de datos no at√≥micos y porque se presentan bastantes na para alguna de las 3 variables que representa. \n",
    "\n",
    "\n",
    "#### **Clusters y anomal√≠as**\n",
    "A continuaci√≥n se justifica el uso de los algoritmos para la creaci√≥n de cluster y detecci√≥n de anomal√≠as:\n",
    "\n",
    "   * Clustering: Se utiliza el algoritmo Kmeans como predeterminado ya que es uno de los algoritmos de clustering m√°s utilizados debido a su eficiencia y simplicidad, es un buen primer acercamiento para la creaci√≥n de clusters en comparaci√≥n con algoritmos mas complejos y que necesitan una mayor comprensi√≥n previa de los datos. En cuanto a sus hiperpar√°metros se establece el valor de n_init en 10, esto implica que el algoritmo se ejecuta 10 veces con diferentes centroides iniciales y se selecciona la mejor asignaci√≥n de clusters para as√≠ reducir la sensibilidad del resultado frente a la inicializaci√≥n aleeatoria. Por √∫ltimo para la elecci√≥n del n√∫mero √≥ptimo de Clusters se utiliza el m√©todo del codo, este metodo utiliza como m√©trica la distorci√≥n para seleccionar el n√∫mero √≥ptimo de Clusters. La distorsi√≥n es una medida de que tan cerca est√°n los puntos dentro de cada cluster respecto a su centroide, mientras menor sea la distorci√≥n mejor es la agrupaci√≥n de puntos en los Clusters, la distorci√≥n tiende a disminuir seg√∫n se aumenta la cantidad de Clusters. El m√©todo del codo utiliza esto √∫ltimo para encontrar el punto donde la distorci√≥n presenta el m√≠nimo cambio al aumentar la cantidad de Clusters, en este caso en particular el n√∫mero √≥ptimo de Clusters es 3.\n",
    "\n",
    "   * Detecci√≥n de anomal√≠as: Se utiliza el algorimo Isolation Forest como algoritmo determinado, este algoritmo de detecci√≥n de anomal√≠as se basa en la idea de que las anomal√≠as son puntos at√≠picos que son m√°s f√°ciles de aislar en comparaci√≥n con los puntos \"normales\" en un conjunto de datos, se escoge este algoritmo ya que se destaca por su robustez frente a valores at√≠picos, su eficiencia para trabajar con grandes cantidades de datos y su facilidad de usar al solo utilizar un hiperpar√°metro, este hiperpar√°metro es 'contamination', contamination controla la proporci√≥n estimada de anomal√≠as en el conjunto de datos. Se establece como una fracci√≥n del total de puntos de datos y representa la cantidad de puntos de datos que se espera que sean anomal√≠as. Se utiliza un valor de 0.05 para este hiperpar√°metro, que es un valor t√≠pico para este algoritmo en particular, este valor significa que se asume que alrededor del 5% de los datos son anomal√≠as.\n",
    "\n",
    "\n",
    "#### **An√°lisis de resultados**\n",
    "Al analizar los clusters algo que se observa a simple vista es que el Cluster N¬∞ 1 est√° conformado por 113319 atletas los cuales todos pertenecen al sexo masculino, mientras que el Cluster N¬∞ 2 est√° conformado por 53381 atletas del sexo femenino y el Cluster N¬∞ 3  est√° conformado por 39459 atletas y tiene una relaci√≥n de 66% atletas hombre y 34% mujeres en el cluster. En los 3 Clusters la distibuci√≥n de medallas es similar, manteniendo una distribuci√≥n cercana al 85% para los atletas sin medalla, un 5% para atletas de medalla de bronce, plata u oro, exceptuando el Cluster N¬∞ 1 que presenta un 4% de atletas con medalla de bronce, plata u oro. Los valores de peso y altura en promedio son mayores para el Cluster de solo hombres, seguido por el Cluster mixto y finalmente el Cluster de mujeres. En cuanto a la edad el cluster de mujeres presenta una edad promedio menor, mientras que los clusters de hombres y mixtos presentan un valor mayor, los 3 cluster presentan una edad promedio menor a la media de los datos escalados. \n",
    "   \n",
    "Luego al analizar las anomal√≠as detectadas, el algoritmo detect√≥ 10,308 anomal√≠as y 195,851 datos que no son anomal√≠as, se observan diferencias en las medias y desviaciones estandar de las variables age, height, weight y year, adem√°s de que en las anomal√≠as se observa una distribuci√≥n mucho mas equitativa en cuanto a los ateltas y si ganaron o no medallas en comparaci√≥n a los datos no an√≥malos donde los atletas que no ganaron medallas representan un poco mas del 80% de los datos, por √∫ltimo las participaciones en distintos deportes y juegos tambi√©n muestra una diferencia en cuanto a las proporciones entre ambos datos.\n",
    "\n",
    "\n",
    "#### **Conclusi√≥n**\n",
    "En la realizaci√≥n de la tarea en cuesti√≥n se obtiene informaci√≥n detallada de los juegos a analizar, obteniendo un resumen de los datos y poder segmentar a los atletas que participaron en los distintos juegos, se obtienen 3 clusters claramente separados al utilizar el algoritmo PCA para poder observarlo en 2 dimensiones, la segmentaci√≥n de los atletas permite poder realizar un an√°lisis mas profundo a cada cluster y los atletas que los componen, adem√°s la detecci√≥n de anomal√≠as permite detectar nuevas maneras de mejorar los datos y la obtenci√≥n de estos en un futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
